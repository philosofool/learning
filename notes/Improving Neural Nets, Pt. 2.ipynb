{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's continue learning about Neural Nets\n",
    "\n",
    "In part 1, we learned about othogonalization and some regularization algorithms.\n",
    "\n",
    "- Othogonalization refers to the idea that we separate the process of eliminating bias from the process of eliminating variance. That is, we find a network that performs very well on our training data first, then we implement regularization (or other processes) to improve dev set performance.\n",
    "\n",
    "- L2 regularization is the most common form. It refers to penalizing the cost function by the squared norm of the linear weights. \n",
    "\n",
    "- Drop-out regularization is another form. It refers to randomly selecting nodes in the network which will not be used during an iteration of training. The result is that no node relies heavily on any node, since it might be zero sometimes. \n",
    "\n",
    "See that notebook for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Gradient Descent\n",
    "\n",
    "This separates our training samples into groups and implements forward and backward propagation on the groups one at a time. \n",
    "\n",
    "```\n",
    "for t = 1,...,5000: ##suppose you have 5,000,000 examples\n",
    "    forward_prop X{t}: ##vectorize on a sub-set of those 5,000,000\n",
    "        Z[1] = W[1]X{t} + b[1]\n",
    "        A[1] = g[1](Z[1])\n",
    "        ...\n",
    "        A[l] = g[l](Z[l])\n",
    "    \n",
    "    \n",
    "    compute_cost:\n",
    "        J{t} = 1/1000 sum(Cost_func(label,prediction) + L2 regularization penalty\n",
    "    ##the 1000's are m, our training sizes, since we broke up the \n",
    "    ##training data into 5,000 samples of 1,000 examples each.\n",
    "    \n",
    "    complete back_prop, using X{t} and Y{t}\n",
    "```\n",
    "\n",
    "A single pass through the above pseudo-code is one **epoch**. Normally, training will require more than one epoch to minimize our cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Mini-batch Gradient Descent\n",
    "\n",
    "This process speeds up learning by using enough data to approximate the gradient in the whole batch while still taking adavantage of vectorization. If X{t} is small, we have a lot of looping and the gradient won't always be very close to the batch gradient. If X{t} is very large, we spend a lot of time computing a gradient for trivial increases in gradient precision compared with a medium sized X{t}.\n",
    "\n",
    "The optimal size (i.e., columns) for X{t} varies, but it is recommended that you chose a power of 2 between 5 (=32) and 8 (=512). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially weighted averages\n",
    "\n",
    "This is a process for smoothing noisy or eratic data where instantaneopus measurements tend to deviate from the mean value in the neighborhood. At least, that's sort of how I see it. Temperature is the example given in the video. How should we express temperature over the course of the year in a graph? Well, you don't want to take too many days of past data, since the temperature two months ago is probably colder or warmer than tomorrow will be. Let's suppose you only want to use recent data (not data from previous years.) A function like this would be a decent first bet:\n",
    "$$\n",
    "v(t) = .8v(t-1) + .2\\theta _t\n",
    "$$\n",
    "Which is just a weighted average. The general form for this is\n",
    "$$\n",
    "v(t) = \\beta v(t-1) + (1 - \\beta)\\theta _t\n",
    "$$\n",
    "This is function expresses the rolling temperature over a number of days\n",
    "$$\n",
    "\\textrm{no. days of the rolling average} = \\frac{1}{1 - \\beta}\n",
    "$$\n",
    "\n",
    "So if $\\beta = .8$ we're approximating the five day average.\n",
    "\n",
    "### Understanding a little more clearly\n",
    "\n",
    "v(t) is an exponentially decaying funciton. Notice that \n",
    "$$\n",
    "v(t) = .2\\theta _t +.8(.2\\theta_{t-1} + .8v(t-2)) \n",
    "$$\n",
    "So we're essentially multiplying each observed temperature day by the size of the function v(t) on that day, and v(t) rapidly approaches 0.\n",
    "\n",
    "### Code Implementation\n",
    "\n",
    "Very memory efficient:\n",
    "```\n",
    "v = 0\n",
    "update: \n",
    "    theta = get_next_theta\n",
    "    v = beta*v + (1-beta)*theta\n",
    "```\n",
    "This is much more memory efficient than keeping the last ten values of v and finding their average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias correction\n",
    "\n",
    "Exponentially weighted averages don't produce good estimates in the inital section of the series unless $\\beta$ is small. To correct this, we take $v_t$ and divide by $(1-\\beta^t)$, which converges to 1 rather quickly. So, for large $t$, we've very close to $v_t$, but for small t, $\\frac{v_t}{1-\\beta^t} \\approx (\\theta_1 + \\ldots + \\theta_t)/t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Momentum\n",
    "\n",
    "In one sentence:\n",
    "\n",
    "> Compute an exponentially weighted average of your gradient and use that to update your weights.\n",
    "\n",
    "This almost always converges faster.\n",
    "During each iteration, compute dW, db on current mini-batch and then compute ```VdW = beta*VdW + (1 - beta)dW``` and same for ```Vdb```. \n",
    "\n",
    "$$\n",
    "v_{dW} = \\beta v_{dW} + (1-\\beta)dW \\\\\n",
    "v_{db} = \\beta v_{db} + (1-\\beta)db \\\\\n",
    "W = W - \\alpha v_{dW}, b = b - \\alpha b_{db}\n",
    "$$\n",
    "\n",
    "In pratice, one doesn't usually need to tune $\\beta$, 0.9 is a strong value, but you can tune it if you want. Sometimes one sees the $1 - \\beta)$ term omitted, which is mathematically equivalent as long as you scale $\\alpha$ corespondingly, by $\\frac{1]{1 - \\beta}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS Prop\n",
    "\n",
    "1. Compute dW and db on a mini batch\n",
    "1. Find SdW and Sdb, SdW = beta * SdW + (1-beta)dW^2, likewise for Sdb.\n",
    "1. Update W and b as W = W - alpha * dW/(sqrt(SdW)), likewise for b\n",
    "1. And just in case sqrt(SdW) is very close to zero, we add a tiny epsilon to prevent W from \"blowing up.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam: RMS Prop + Momentum\n",
    "\n",
    "This is one of the few optimization algorithms that's been shown to be consistently successful. \n",
    "\n",
    "1. Set VdW, SdW, Vdb, Sdb to 0.\n",
    "1. on each iteration, compute derivatives for mini-batch\n",
    "    1. VdW = beta_1 * VdW + (1-beta_1)dW, Vdb = (same)\n",
    "    1. SdW = beta_2 * VdW + (1-beat_2)dW^2\n",
    "    1. We do implement bias correction.\n",
    "    1. VdV = VdW / (1 - beta_1^t), and likewise for hte other three\n",
    "    1. Update W = W - alpha * VdW/(sqrt(SdW) + epsilon), etc. \n",
    "    \n",
    "### Hyperparameters with Adam\n",
    "\n",
    "- $\\alpha$ needs to be tuned.\n",
    "- $\\beta_1$ usually default as 0.9\n",
    "- $\\beta_2$ ysyally default as 0.999\n",
    "- $\\epsilon$ usually $10^8$. \n",
    "\n",
    "The name Adam is for Adaptive moment estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "\n",
    "The idea is to reduce the learning rate with each epoch. \n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{1}{1 + \\textrm{decay rate} \\times \\textrm{epoch number}}\\alpha_0\n",
    "$$\n",
    "\n",
    "There are other function that people use (exponential decay, etc.)\n",
    "\n",
    "Ng sees learning rate decay as lower down his list of ways to tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2,\n",
       " 0.13333333333333333,\n",
       " 0.1,\n",
       " 0.08,\n",
       " 0.06666666666666667,\n",
       " 0.05714285714285715,\n",
       " 0.05,\n",
       " 0.044444444444444446,\n",
       " 0.04,\n",
       " 0.03636363636363637,\n",
       " 0.03333333333333333,\n",
       " 0.03076923076923077,\n",
       " 0.028571428571428574,\n",
       " 0.02666666666666667,\n",
       " 0.025,\n",
       " 0.023529411764705882,\n",
       " 0.022222222222222223,\n",
       " 0.021052631578947368,\n",
       " 0.02,\n",
       " 0.01904761904761905]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decay_rate = .5\n",
    "[.2/(1+decay_rate*epoch_number) for epoch_number in range(0,20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local minima, local optima, etc\n",
    "\n",
    "Ng basically says \"we used to worry about that, but in high dimensional spaces, it doesn't really happen. Almost all regions where there's a zero gradient are saddle points.\"\n",
    "\n",
    "_Plateaus_ are a problem. A plateaus is just a large region where the derivative is close to zero. They slow things down a fair amount; optimizations like Adam help a bunch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ^: 'float' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-871c853b780f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;36m.1\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ^: 'float' and 'float'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.randn(1,10).reshape((1,10))\n",
    "X[0,1:3]\n",
    ".1^.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
