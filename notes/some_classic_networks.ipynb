{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Studies in Neural Nets\n",
    "\n",
    "We look at some successful networks to gain insight on how to build NNs. See LeCun et al. (1998) \"Gradient Based Learning applied to document recognition\" in [Journal not mentioned].\n",
    "\n",
    "## LeNet-5 \n",
    "\n",
    "Build for recognizing 32x32 greyscale images of handwritten digits.\n",
    "\n",
    "32x32x1 --->\n",
    "\n",
    "CONV: 6 5x5 filters, stride 1\n",
    "28x28x6 --->\n",
    "\n",
    "AvPool: f=2, s=2\n",
    "14x14x6 --->\n",
    "\n",
    "CONV: 16 5x5 filters, stride 1\n",
    "10x10x16 --->\n",
    "\n",
    "AvPool: f=2, s=2\n",
    "5x5x16 --->\n",
    "\n",
    "FC : 400 ---> 120 ---> 84 --->\n",
    "SOFTMAX (10) ---> y-hat\n",
    "\n",
    "### Comments\n",
    "\n",
    "The use of average pooling is much less common today. (My speculation: averages tend to be pretty average and can washout, especially with f > 2, but representing the most extreme values tends to give a sense of where large changes happen.)\n",
    "\n",
    "The original used sigmoid and tanh activations, not relu. COmputational power limited the ability of the network and there's a fair amount of discussing how to apply filters to reduce complexity.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "\n",
    "Krizhevsky et al. (2012) ImageNet Clasification with deep convolutional neural networks.\n",
    "\n",
    "Input, 227x227x3 (RGB) --->\n",
    "\n",
    "CONV: 96 11x11, stride 4: 55x55x96 --->\n",
    "\n",
    "MAX-Pool: 3x3, stride =2: 27x27x96 --->\n",
    "\n",
    "CONV: 256 5x5 Same : 27x27x256 --->\n",
    "\n",
    "MaxPool 3x3, s = 2: 13x13,256--->\n",
    "\n",
    "CONV 3x3 Same 384 filders --->\n",
    "\n",
    "CONv 3x3 x 384 Same ---> (yes, they repeated that)\n",
    "\n",
    "CONV smae 3x3 x 256 same --->\n",
    "\n",
    "MaxPool 3x3, s = 2: 6x6x256 --->\n",
    "\n",
    "Flatten: 9216 x 1:\n",
    "\n",
    "FC 4096 --> 4096 --> Softmax(100)\n",
    "\n",
    "### Comments\n",
    "\n",
    "AlexNet has about 1000 times more parameters than LeNet. Relu was the activation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 96)\n",
      "(None, 13, 13, 256)\n",
      "(None, 13, 13, 384)\n",
      "(None, 13, 13, 384)\n",
      "(None, 13, 13, 256)\n",
      "Model: \"AlexNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 57, 57, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 58,322,314\n",
      "Trainable params: 58,322,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def alex_net():\n",
    "    '''\n",
    "    Returns an uncompiled AlexNet\n",
    "    '''\n",
    "    inputs = keras.Input(shape=(227,227,3))\n",
    "    x = keras.layers.Conv2D(96, kernel_size=11, strides=4, padding='same', activation='relu')(inputs)\n",
    "    x = keras.layers.MaxPool2D(pool_size=3, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=5, strides=1, padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=3, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    x = keras.layers.Conv2D(384, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    x = keras.layers.MaxPool2D(pool_size=3, strides=2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(1000, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name = 'AlexNet')\n",
    "    return model\n",
    "alex_net().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16\n",
    "\n",
    "This paper focused on using simple filters and pooling, rather than the more comlplex choices of the others. It's later (2015). The networks uses only 3x3,s=1,same filters and 2x2,s=2 maxpooling.\n",
    "\n",
    "Input 224x224x3 --->\n",
    "\n",
    "CONV(64)x2 ---> MAXPOOL --->\n",
    "\n",
    "CONV(128)x2 ---> MAXPOOL --->\n",
    "\n",
    "CONV(256)x3 + POOL ---> \n",
    "\n",
    "CONV(512)x3  + POOL --->\n",
    "\n",
    "CONV(512) + POOL --->\n",
    "\n",
    "Flatten ---> FC(4096)-->FC(4096)--->SOFTMAX\n",
    "\n",
    "### Comments\n",
    "\n",
    "There's a lot of simplicity here. The number of filters is roughly doubled each pass, with a small increase in the number of passes in each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG-16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              411045888 \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 439,559,464\n",
      "Trainable params: 439,559,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv(filters):\n",
    "    return keras.layers.Conv2D(filters=filters, kernel_size=3, activation='relu', strides=1, padding='same')\n",
    "\n",
    "def pool():\n",
    "    return keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "\n",
    "def VGG_16():\n",
    "    inputs = keras.Input(shape=(224,224,3))\n",
    "    x = conv(64)(inputs)\n",
    "    x = conv(64)(x)\n",
    "    x = pool()(x)\n",
    "    x = conv(128)(x)\n",
    "    x = conv(128)(x)\n",
    "    x = pool()(x)\n",
    "    x = conv(256)(x)\n",
    "    x = conv(256)(x)\n",
    "    x = conv(256)(x)\n",
    "    x = pool()(x)\n",
    "    x = conv(512)(x)\n",
    "    x = conv(512)(x)\n",
    "    x = conv(512)(x)\n",
    "    x = pool()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = keras.layers.Dense(1000, activation='softmax')(x)\n",
    "    return keras.Model(inputs, x, name='VGG-16')\n",
    "VGG_16().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet and Residual Blocks\n",
    "\n",
    "A _residual block_ is a fundamental component of a ResNet. These help avoid very deep networks where exploding and vanishing gradients can become a problem. The seminal paper is He et al. (2015), \"Deep Residual Networks for Image Recognition.\"\n",
    "\n",
    "Very deep neural networks can actually be worse than their simipler counterparts on the training data. ResNet helps to avoid this problem.\n",
    "\n",
    "### Setting up the Residuals Model\n",
    "\n",
    "Let's start with a simple, standard model of two layers: we begin with an input layer $a^{[l]}$ which we pass forwar to a linear function, $z^{[l+1]} = Wa^{[l]} + b$ and then a non-linear function $a^{[l+1]} = g(z^{[l+1]})$ (relu). This is then the input to another linear/non-linear pair of transformation. We refer to the result of these as $a^{l+2}$.\n",
    "\n",
    "To use residuals, we sum the activation layer $a^l$ into the activation prior to $a^{l+2}$. That is, $$a^{l+2} = g(z^{l+2} + a^{l})$$.\n",
    "\n",
    "And that a residual block: a \"skip connection\" that adds the activation $a^{[l]}$ to $z^{[l+2]}$ when calculating $a^{[l+2]}$ for each layer $a^{[l+2]}$.\n",
    "\n",
    "### Why does this work?\n",
    "\n",
    "The short answer is that if additional layers don't improve the network, a ResNet easily reduces to the identity funciton so additional layers can't make the network worse than a prior function. If I follow correctly, this implies that the early network layers are likely to improve \"first\" while the later ones can \"catch up\" once the first layers have a strong "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x1, or Network in Network Convolutions\n",
    "\n",
    "Wait, a 1x1 convolution? Sure--the number of filters is a non-trivial matter. \n",
    "\n",
    "Suppose you have a 6x6x30 volume and you convovle with a 1x1xn filter: the result is a 6x6xn volume, which is not a trivial transform. Even if the number of filters equals the number of channels on the input layer, it adds non-linearity.\n",
    "\n",
    "### Bottleneck Layers\n",
    "\n",
    "A 1x1 CONV filter can also be used to reduce computations.\n",
    "\n",
    "For example, if you had a large volume, say 28x28x192 and applied a 5x5, f=32 convolution, you would need about 120M computations: 28x28x32 x 5x5x192.\n",
    "\n",
    "Instead, we can reudce the volume with a 1x1 convolution and then apply a 5x5, f=32 convolution on it. For example, CONV1 1x1x16, CONV2 5x5x32...\n",
    "\n",
    "CONV1 requires  28x28x16x192 = 2.4M computations.\n",
    "\n",
    "CONV2 requires 28x28x32 x 5x5x16 = 10M computations\n",
    "\n",
    "This doesn't reduce network strength very much if our bottle neck (the 1x1 layer) is \"within reason.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Module\n",
    "\n",
    "An inception module passes an input activation to multiple filters and concatenates their output for prediction. \n",
    "\n",
    "Here's the idea:\n",
    "\n",
    "- input = 32x32x192.\n",
    "- bottleneck1 = CONV1x1, f=16\n",
    "- CONVx5 = bottleneck1 * 5x5, f=3232\n",
    "- bottleneck2 = CONV1x1, f=16\n",
    "- CONVx3 = bottleneck2 * 3x3, f=64\n",
    "- CONvx1 = CONV1x1, f=32\n",
    "- POOL = MaxPool 3x3,s=1,padding='same'\n",
    "- CONCAT = concatenate(CONVx5,CONVx3,CONx1,POOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "There are many networks on the internet. These can be used to train your own network. For example, if you want to build a Pepper-Eleanor-Ody recognizer for images, you will probably achieve good results using a pretrained network. In steps:\n",
    "\n",
    "1. Download a pretrained, open-source network (e.g., from GitHub)\n",
    "1. Freeze the layers except the softmax layer, which you re-write as a 4 value softmax output.\n",
    "1. Train using your own data.\n",
    "\n",
    "If you have large amounts of data, you can consider freeze fewer of the layers, starting with downstream ones. For example, you could freeze all but the final FC layers.\n",
    "\n",
    "Of course, if you have a ton a data and some computational power (or time), you could retrain the whole network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "You've covered this before: rotation, color shift, mirroring, etc. _PCA (Principle Component Analysis) is not something you've heard about with data augmentation before_. PCA performs a color shift without changing the overall tint of the picture: if you have an RGB with high GB and low R values in most places, it performs a shift on GB but leaves R alone. It's in the AlexNet paper cited above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"The State of Computuer Vision\"\n",
    "\n",
    "Two sources of learning knoweldge in a system:\n",
    "- labeled data\n",
    "- Human engineered architechture/features\n",
    "\n",
    "We still don't have a lot of data for all the tasks. Insightful engineering is necessary for those tasks where we have less data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
