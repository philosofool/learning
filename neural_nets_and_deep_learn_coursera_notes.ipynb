{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning\n",
    "\n",
    "A simple regression function takes size of a house as an input and returns price. In the example, a rectified linear unit was given. RELU is the acronym here.\n",
    "\n",
    "In a more complex example, it is suggested that by adding a layer, the network can be trained to detect relevant features. For example, in housing price the hidden layers might become sensitive to school quality, family size and walkability, all of which affect housing price. All the neurons are connected to the input layer but the weighting will determine which neurons affect the hidden layer activation. Of course, with enough data, the network is trained, so we don't have to engineer the features read in the hidden layers.\n",
    "\n",
    "> To use a topic of interest to me, a home run predictor might have a hidden layer that detects launch angle, velocity, field direction, and ball park. These would typically be sufficient to detect whether a batted ball will be a homerun.\n",
    "\n",
    "Note that the meaning of the features will may be difficult to interpret. Using my HR example, you _may_ find that launch angle is an implicit feature. But you may _not_ find it. That is, of course, part of the point: NNs allow us to \"design\" systems without designing the features they need to work well.\n",
    "\n",
    "## Network Types\n",
    "\n",
    "A _standard neural network_ might be used in online advertising, real estate pricing. \n",
    "\n",
    "A _convollutional network (CNN)_ might be used in image recognition.\n",
    "\n",
    "A _recurrent neural network (RNN)_ might be use with language or other sequential data. \n",
    "\n",
    "## Structured and Unstructured Data\n",
    "\n",
    "They just give examples, but structured data is data that has been recorded and usually takes discrete or continuous values such as housing prices or whether something is a cat; unstructured data is data that's not been so classified, such as an image. \n",
    "\n",
    "## Scale drives NN\n",
    "\n",
    "Neural Network outperform other learning models when (1) we have lots of data and (2) to the degree that the network is sophisticated.\n",
    "\n",
    "There's a graph of network performance that looks like logarithmic functions. In the region of limited amounts of data, the performance ordering is not well defined. in that region, feature engineering tends to be of the essence in determining algorithm performance.\n",
    "\n",
    "### Algorithmic advancements are also important\n",
    "\n",
    "Algorithms:\n",
    "\n",
    "1. improve computational speed, for example RELU is way faster in gradient descent than sigmoid. \n",
    "1. _It sounded like there was going to be a list of reasons why algorithms improve the process, over and above the data/computational changes that have accelerated deep learning._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression\n",
    "\n",
    "We want a function that expresses the probability of y = 1 given x, $\\hat{y} = P(y = 1 | x)$ where $0 \\le \\hat{y} \\le 1$. \n",
    "$$\n",
    "\\hat{y} = \\sigma(w^{T} + b)\n",
    "$$\n",
    "$/sigma$ is the sigmoid function. \n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e ^ {-z}}\n",
    "$$\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "The phrase loss function and cost function seem to be used interchangably. (_Nope. But good eye. See below._)Anyway, you might thing we want something like \n",
    "$$\n",
    "L(\\hat{y},y) = \\frac{1}{2}(\\hat{y}-y)^{2}\n",
    "$$\n",
    "but that makes for a poor choice with gradient descent. (More on GD later.)\n",
    "\n",
    "In order to get a convex optimization problem, we like:\n",
    "$$\n",
    "L(\\hat{y},y) = -(y \\textrm{log} \\hat{y} + (1-y)\\textrm{log}(1-\\hat{y}))\n",
    "$$\n",
    "\n",
    "Hah! The loss function is defined for a single example; the cost function is the mean loss for all examples.\n",
    "$$\n",
    "J(w,b) = \\frac{1}{m}\\sum\\limits_{i=1}^m L(\\hat{y}^{(i)},y^{(i)})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The cost function defines a convex hypersurface. Suppose we are trying to minimize $J(w)$. Each step of gradient descent updates $w$ according to the following rule:\n",
    "$$\n",
    "w := w - \\alpha \\frac{dJ(w)}{dw}\n",
    "$$\n",
    "\n",
    "Where $\\alpha$ is the learning rate and these are deriviatives.\n",
    "\n",
    "This makes sense when you think about it. Our derivative represents a rate of change, which will be zero at the minimum of the hypersurface; thus, at that minimum, $w$ updates to $w$, and elsewhere, it moves in the direction of the minimum.\n",
    "\n",
    "Of course, what we're actually trying to optimize are $w$ and $b$ and the functions we care about are...\n",
    "$$\n",
    "w := w - \\alpha \\frac{\\partial J(w,b)}{\\partial w}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\n",
    "b := b - \\alpha \\frac{\\partial J(w,b)}{\\partial b}\n",
    "\n",
    "$$\n",
    "\n",
    "Latex appears to be broken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation Graphs\n",
    "\n",
    "SUppose you have a function, J(a,b,c) = 3(a + bc). We can think of this function in three steps:\n",
    "$$\n",
    "u = bc \\\\\n",
    "v = a + u \\\\\n",
    "J = 3v\n",
    "$$\n",
    "We can then ask what various derivatives are. E.g., what is $\\frac{dJ}{dv}$? It's 3. \n",
    "\n",
    "We can compute others by the _chain rule_, which says\n",
    "$$\n",
    "\\frac{dx}{dz} = \\frac{dx}{dy}\\frac{dy}{dz}\n",
    "$$\n",
    "\n",
    "When we write code, we're usually interested in a final output variable. By convention, we name derivatives like $\\frac{dJ}{dv}$ ```dv```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Derivatives\n",
    "\n",
    "We can use computation graphs to handle the backward propagation step.\n",
    "\n",
    "\n",
    "$\\hat{y} = \\sigma(w^{T} + b)$\n",
    "\n",
    "a = $\\sigma(z) = \\frac{1}{1 + e ^ {-z}}$\n",
    "\n",
    "$L(\\hat{y},y) = -(y \\textrm{log} \\hat{y} + (1-y)\\textrm{log}(1-\\hat{y}))$\n",
    "\n",
    "We compute the loss on a single example with the final equations. Thus, the first derivative we want is $\\frac{dL(\\hat{y},y)}{da}$.\n",
    "\n",
    "What we are looking for is how much to change $w_1, w_2 \\ldots w_n$, our logistic regression weights. It turns out that the relevant amounts are found with $x_i\\frac{dL}{d\\hat{y}}$:\n",
    "$$\n",
    "w_i := w_i - \\alpha \\frac{dL}{dw_i} = w_i - \\alpha x_i\\frac{dL}{d\\hat{y}}\n",
    "$$\n",
    "\n",
    "In order to find the cost (cf. loss), we need to take the mean loss for our $m$ training examples. Logically, this means some ```for``` loops with each of our examples to find the update amounts, as above, and then taking the average. However, this is equivalent to a much faster vectorized process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vect version: 114.34412002563477ms\n",
      "Loop version: 964.1385078430176ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1_000_000)\n",
    "b = np.random.rand(1_000_000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Vect version: \"+ str((toc-tic)*1000) + \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1_000_000):\n",
    "    c += a[i]*b[i]\n",
    "toc = time.time()\n",
    "print(\"Loop version: \"+ str((toc-tic)*1000) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "Vectorization uses SIMD (Single Instruction Mutliple Data) rather than a for loop. Numpy is, of course, full of elementwise operations for vectors:\n",
    "```\n",
    "np.log(v) ## elementwise log for values in v.\n",
    "np.abs(v) ##abs value\n",
    "np.maximum(v,0) #the larger of v and 0\n",
    "v**2 ##square\n",
    "v+1 ##increment v\n",
    "etc.\n",
    "```\n",
    "Consider a block of code for finding cost:\n",
    "```\n",
    "##This is obviously not real code.\n",
    "\n",
    "J = 0, dw1 = 0, dw2 = 0, ..., db = 0\n",
    "for i in range(1,m):\n",
    "    ##calculate each instance\n",
    "    z_i = w.T_i + b\n",
    "    a_i = sigmoid(z_i)\n",
    "    J += -(y_i * log(a_i) + (1 - y_i)log(1-a_i) ##loss function\n",
    "    dz_i = a_i - y_i\n",
    "    for i in [dw1, dw2 ...]:\n",
    "        dw_i += x[i]*dzi\n",
    "J = J/m, dw1 = dw1/m, dw2 = dw2/m ##find their means\n",
    "```\n",
    "\n",
    "We can vectorize this an eliminate a for loop by replacing explicit ```dw1 = 0, dw2 = 0,....``` with ```dw = np.zeros``` and eliminating the final for loop by ```dw += dzi```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Logistic Regression\n",
    "\n",
    "For each training example, we need to find $z_i = w_i^Tx_i+b$.\n",
    "\n",
    "To do that, we find $Z = w^TX + \\hat{b}$, where $\\hat{b}$ is just a row vector length $m$ of $b$s.\n",
    "\n",
    "Then we find the sigmoid of $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12689b7d7bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##This is the step in python, using an arbitrary example.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "##This is the step in python, using an arbitrary example.\n",
    "\n",
    "X = np.array([0,1,2,3,4,5,6,7,8]).reshape(3,3)\n",
    "w = np.array([2,3,4])\n",
    "b = 2\n",
    "Z = np.dot(w.T,X\n",
    "          ) + b\n",
    "Z\n",
    "\n",
    "##The sigmoid calculation is left as an exercise for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Gradient\n",
    "\n",
    "To vectorize the gradient, we're going to find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Numpy objects\n",
    "\n",
    "numpy objects that look like row vectors may not be, and they will misbehave if used like one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is not a real vector\n",
    "print(\"A vector-looking thing\")\n",
    "not_v = np.arange(6)\n",
    "print(not_v)\n",
    "\n",
    "## we can see this by checking the shape.\n",
    "print(not_v.shape)\n",
    "\n",
    "## this is a real vector; it's a row vector:\n",
    "print(\"A real vecor\")\n",
    "v = np.arange(6).reshape(1,6)\n",
    "print(v)\n",
    "print(v.shape)\n",
    "\n",
    "#Notice the behavior when we take the transpose.\n",
    "print(\"Their transposes\")\n",
    "print(not_v.T) \n",
    "print(v.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the cost fucntion\n",
    "\n",
    "If $y = 1$, $p(y|x) = \\hat{y}$\n",
    "\n",
    "If $y = 0$, $p(y|x) = 1 - \\hat{y}$\n",
    "\n",
    "These are both true if and only if:\n",
    "$$p(y|x) = \\hat{y}^y(1 - \\hat{y})^{1 - y}$$\n",
    "\n",
    "(It's fun to notice why that's correct by noting what happens when y is 0 and when it's 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(3, 3)\n",
    "b = np.random.randn(3, 1)\n",
    "c = a*b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.25467577],\n",
       "        [ 1.42151296],\n",
       "        [ 0.4017047 ]],\n",
       "\n",
       "       [[-0.19145451],\n",
       "        [ 1.47867666],\n",
       "        [ 0.0704399 ]],\n",
       "\n",
       "       [[ 0.30746377],\n",
       "        [-0.79876817],\n",
       "        [ 0.09971697]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(3,3,3,1)\n",
    "b = x.reshape(x.shape[0],-1)\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Representation\n",
    "\n",
    "We have an input layer, denoted $a^{[0]}$; previously we called this $X = {x_1,x_2,... x_n}$.\n",
    "\n",
    "Our next layer is a hidden layer, denoted $a^{[1]} = a^{[1]}_1,...a^{[1]}_n$\n",
    "\n",
    "There may be additional layers, but the final layer is the output layer, which is a real number value which equals $\\hat{y}$. \n",
    "\n",
    "Note that this is a two layer network (if it has one hidden layer and an output layer). The inputs aren't neurons, I guess, so that's why it has such a name.\n",
    "\n",
    "Associated with each layer are parameters $w, b$ with suitable superscripts (e.g., $w^{[1]}, b^{[1]}$). $w^{[1]}$ with have a number of rows equal to the number of neurons in $a^{[1]}$ and a number of columns equal to the number of features in $a^{[0]}$; $b^{[1]}$ is column vector with rows for each neuron in $a^{[1]}$ .\n",
    "\n",
    "In general, the parameters associated with each layer are derived from the number of neuron in the layer and the number of neurons that are inputs to it. The number of rows equals the layers number of neurons, the number of columns equals the number of input neurons.\n",
    "\n",
    "Note that a logistic regression is basically a single layer network with a single neuron in the output layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Output\n",
    "\n",
    "Each node computes a linear weighting of the input values and then computes the activation function (which we're still assuming is the sigmoid.)\n",
    "\n",
    "Thus $a^{[l]}_i$ computes $z^{[l]}_i = w^{[l]T}_i x + b^{[l]}_i$ and computes $\\sigma (z^{[l]}_i)$\n",
    "\n",
    "Not surprisingly, we're going to stack all this together to vectorize the process. This gives us two big, neat matrixy equations:\n",
    "\n",
    "$$\n",
    "z^{[1]} = W^{[1]}x + b^{[1]}\\\\\n",
    "a^{[1]} = \\sigma(z^{[1]})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "The tanh function:\n",
    "$$a = tanh(z) = \\frac{e^{z}-e^{-z}}{e^{z} + e^{-z}}$$\n",
    "This has the effect of \"centering\" the activation function around 0 so it provides a sort of normalization. It otherwise is just a permutation of the sigmoid. It is almost always better than sigmoid, however. The one notable exception is that in the final output layer for a binary classification, it makes sense for the output to be in a range of 0 to 1. So, in the hidden layers, we would usually prefer tanh but perhaps prefer sigmoid in the final layer.\n",
    "\n",
    "The rectified linear unit (ReLU):\n",
    "$$\n",
    "ReLU(z) = max(0,z)\\\\\n",
    "\\partial ReLU(z)  = 0 \\textrm{ if }  z < 0; 1 \\textrm{ if } z > 0\n",
    "$$\n",
    "\n",
    "Leaky ReLU. This is fun. It looks like a simple hack to solve the uniform zero derivative where $z < 0$. You just give it a small positive slope.\n",
    "\n",
    "You can choose the slope for z < 1; something small like:\n",
    "$$\n",
    "\\textrm{leaky ReLU}(z) = max(0.01,z)\\\\\n",
    "$$\n",
    "\n",
    "**ReLU has become the default.** However, there are problems where other functions might be superior. See [this simulator](http://playground.tensorflow.org); the spiral problem is most easily solved with tanh; try it and see if you don't believe me. (BTW, you find a pretty good solution for the spiral with a two hidden layer network containing 8 neurons and 2 neurons. Include X1 and X2 and their sines as the features.  Learning rate = .03.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives of the activation functions\n",
    "For the sigmoid function\n",
    "$$\n",
    "\\frac{d}{dz}\\sigma(z) = \\sigma(z)(1 - \\sigma(z)) \n",
    "$$\n",
    "\n",
    "For tanh\n",
    "$$\n",
    "\\frac{d}{dz}tanh(z) = 1 - tanh^2(z)\n",
    "$$\n",
    "\n",
    "See above for ReLU.\n",
    "\n",
    "Note that ReLU is not defined for $z = 0$. The probability that you're going to stumble on z=0 and throw and exception in your code is tiny. A solution is just to set this point's derivative to either 1 or 0 to avoid the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The propagation equations\n",
    "\n",
    "Forward, you pretty much know these:\n",
    "$Z^{[1]} = W^{[1]}X + b^{[1]}$\n",
    "\n",
    "$A^{[1]} = g^{[1]}(Z^{[1]})$\n",
    "\n",
    "As so on for the rest of the layers, which take the output of the previous layer in place of X.\n",
    "\n",
    "Backward:\n",
    "\n",
    "$dZ^{[2]} = A^{[2]} - Y$\n",
    "\n",
    "$ dW^{[2]} = \\frac{1}{m} dZ^{[2]}A^{[1]T}$\n",
    "\n",
    "```\n",
    "db^{[2]} = \\frac{1}{m}np.sum(dZ^{[2]}, axis = 1, keepdims = True)\n",
    "##this is in code because we're summing rows of a matrix\n",
    "```\n",
    "\n",
    "$dZ^{[1]} = W^{[2]T}dZ^{[2]} \\times g^{[1]}(Z^{[1]})$\n",
    "(This $\\times$ indicates elementwise multiplication.\n",
    "\n",
    "$dW^{[1]} = \\frac{1}{m}dZ^{[1]}X^T$\n",
    "\n",
    "```db^{[1]} = 1/m*np.sum(dZ[1],axis = 1, keepdims = True)```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Initialization\n",
    "\n",
    "If you don't initialize randomly, every neuron calculates the same function and has the same derivative so your network reduces to a single neuron. We initialize randomly to avoid this. We usually multiply our random numbers by a small constant because if the numbers are larger, learning is slower (look at the derivaties, ~=0, at the extremes of tanh.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Networks\n",
    "\n",
    "Networks are typically called \"deep\" when the number of layers is greater than 2, i.e., when there are multiple hidden layers prior to the output layer.\n",
    "\n",
    "### Notational Stuff\n",
    "\n",
    "$L$ denotes the number of layers \n",
    "\n",
    "$n^{[l]}$ units in layer l\n",
    "\n",
    "$a^{[l]}$ activations in l\n",
    "\n",
    "$a^{[l]} = g^{[l]}(z^{[l]})$ by the way\n",
    "\n",
    "$w^{[l]}$ weights for $z^{[l]}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation in a deep NN\n",
    "\n",
    "$z^{[l]} = W^{[l]}a^{[l-1]}+b^{[l]}$\n",
    "\n",
    "$a = g^{[l]}(z^{[l]})$\n",
    "\n",
    "We vectorize in the expected way (or at least, the way I expected). Note that we will need a for loop to complete the propagation for each layer; that cannot be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about the dimensions\n",
    "\n",
    "The output of each layer, $z^{[l]}$, is the result of $W^{[l]}a^{[l-1]} + b^{[l]}$. The dimensions of the output layer are thus $(n^{[l]},1)$ and the input layer dimensions are $(n^{[l-1]},1)$. $W^{[l]}$ must therefore have dimensions $(n^{[l]},n^{[l-1]})$. $b$ is obviously a colmn vector with the dimensions of $(n^{[l]},1)$.\n",
    "\n",
    "When we vectorize, the 1's are replaced with m's, because we have m training examples. \n",
    "\n",
    "Ng says to use this to help debug code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why deep networks?\n",
    "\n",
    "\n",
    "### \"Feature Construction\" explanation\n",
    "The first hidden layer of a network constructs features of the input layer. These are passed as inputs to the next layer. These features are then inputs to constuct a next level of features, typically of a higher level of complexity, from the features constructed at the prior level. At each layer, we get a little more complexity in the construction.\n",
    "\n",
    "The example given is face recognition in a three layer network (the example is slightly artificial in the complexity of the network.) Layer one detects edges, layer two detects facial components (eyes nose, mouth, chin, etc.), layer three detects faces (which are composed of facial components.) \n",
    "\n",
    "Here's a baseball example (since I like those): suppose you have a bunch of hittrack data. You will have angles and speeds in the input features. At a next level you might generate x, y and z velocities. At the third level, distances traveled, landing position, etc. The final level could classify the batted ball as a home run, fly ball out or other type of batted ball.\n",
    "\n",
    "### Circuit Theory explanation\n",
    "\n",
    "Informally, this says that there are functions that can be computed in a deep network that would require an exponentially larger network to compute with a shallow network.\n",
    "\n",
    "XOR provides an example. You need just log(n) hidden units to computer XOR for n features using a deep network. To do the same with a shallow network of one layer, you need $2^n$ units.\n",
    "\n",
    "### Branding\n",
    "\n",
    "I love this: he just admits that the phrase \"deep learning\" is a recentish brand of an existing model and it's taken off because it sounds sexy. That's really an explanation for why we talk so much about deep learning, not an explanation of why it works. But it's funny to note it because "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "The parameters of the model are $W^{[1]}$, $b^{[1]}$, $W^{[2]}$, etc. These are tuned by the forward and backward propagation.\n",
    "\n",
    "The hyperparameters include other values that we need to specify. Tuning our network generally requires tuning our hyperparameters. Our hyperparameters include:\n",
    "- learning rate\n",
    "- number of iterations.\n",
    "- num. of hidden layers\n",
    "- num of layer units\n",
    "- choice of activation function.\n",
    "\n",
    "Later we will learn about a few more, like momentum, regularization, batch size.\n",
    "\n",
    "\n",
    "**\"Applied deep learning is a very empirical process\"**\n",
    "\n",
    "1. There's a fair amount of trial and error involved, iteration and refining.\n",
    "1. Developing intuitions is a matter of experience.\n",
    "1. Experiences in one domain may or may not translate to another.\n",
    "1. Even developed networks may find that re-tuning some parameters is valuable after time: changes to data, changes in hardware, etc. can all allow for further tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
